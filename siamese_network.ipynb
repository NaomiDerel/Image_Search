{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - Similiarity Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook details the process of choosing the similarity function that determines the images that are similar to a given image.\n",
    "The implementation of the network is based on the Siamese network implementation. This class of networks is known to be more robust to class imbalance, so it fits the data on which we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# split the data into training and testing\n",
    "train_data = data.sample(frac=0.8, random_state=0)\n",
    "test_data = data.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        # Setting up the Sequential of CNN Layers\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, kernel_size=11, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "        )\n",
    "        \n",
    "        # Adaptive pooling layer to ensure the output size is consistent\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((6, 6))  # Adjust pooling size to handle dynamic input\n",
    "        \n",
    "        # Defining the fully connected layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(256 * 6 * 6, 1024),  # Input size adjusted for adaptive pooling\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            \n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "        \n",
    "    def forward_once(self, x):\n",
    "        # Forward pass \n",
    "        x = self.cnn1(x)\n",
    "        x = self.adaptive_pool(x)  # Adaptive pooling to standardize the feature map size\n",
    "        x = x.view(x.size(0), -1)  # Flatten the feature map\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # Forward pass of input 1\n",
    "        output1 = self.forward_once(input1)\n",
    "        # Forward pass of input 2\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the model\n",
    "# class SiameseNetwork(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SiameseNetwork, self).__init__()\n",
    "#         # Setting up the Sequential of CNN Layers\n",
    "#         self.cnn1 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 96, kernel_size=11,stride=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
    "#             nn.MaxPool2d(3, stride=2),\n",
    "            \n",
    "#             nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
    "#             nn.MaxPool2d(3, stride=2),\n",
    "#             nn.Dropout2d(p=0.3),\n",
    "\n",
    "#             nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            \n",
    "#             nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(3, stride=2),\n",
    "#             nn.Dropout2d(p=0.3),\n",
    "#         )\n",
    "#         # Defining the fully connected layers\n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Linear(30976, 1024),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout2d(p=0.5),\n",
    "            \n",
    "#             nn.Linear(1024, 128),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            \n",
    "#             nn.Linear(128,2))\n",
    "        \n",
    "#     def forward_once(self, x):\n",
    "#         # Forward pass \n",
    "#         output = self.cnn1(x)\n",
    "#         output = output.view(output.size()[0], -1)\n",
    "#         output = self.fc1(output)\n",
    "#         return output\n",
    "\n",
    "#     def forward(self, input1, input2):\n",
    "#         # forward pass of input 1\n",
    "#         output1 = self.forward_once(input1)\n",
    "#         # forward pass of input 2\n",
    "#         output2 = self.forward_once(input2)\n",
    "#         return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on:\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x0, x1, y):\n",
    "        # euclidian distance\n",
    "        diff = x0 - x1\n",
    "        dist_sq = torch.sum(torch.pow(diff, 2), 1)\n",
    "        dist = torch.sqrt(dist_sq)\n",
    "\n",
    "        mdist = self.margin - dist\n",
    "        dist = torch.clamp(mdist, min=0.0)\n",
    "        loss = y * dist_sq + (1 - y) * torch.pow(dist, 2)\n",
    "        loss = torch.sum(loss) / 2.0 / x0.size()[0]\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "network = SiameseNetwork().cuda()\n",
    "# Decalre Loss Function\n",
    "criterion = ContrastiveLoss()\n",
    "# Declare Optimizer\n",
    "optimizer = optim.Adam(network.parameters(), lr=1e-3, weight_decay=0.0005)\n",
    "def train_siamese_network(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (img1, img2, labels) in enumerate(train_loader):\n",
    "            # Move tensors to the appropriate device\n",
    "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output1, output2 = model(img1, img2)\n",
    "            loss = criterion(output1, output2, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "            if (i + 1) % 10 == 0:  # Print every 10 batches\n",
    "                print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 10:.4f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "    return model\n",
    "\n",
    "model = train_siamese_network()\n",
    "torch.save(model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training loop\n",
    "# network = SiameseNetwork().cuda()\n",
    "# # Decalre Loss Function\n",
    "# criterion = ContrastiveLoss()\n",
    "# # Declare Optimizer\n",
    "# optimizer = optim.Adam(network.parameters(), lr=1e-3, weight_decay=0.0005)\n",
    "# #train the model\n",
    "# def train():\n",
    "#     loss=[] \n",
    "#     counter=[]\n",
    "#     iteration_number = 0\n",
    "#     for epoch in range(1,config.epochs):\n",
    "#         for i, data in enumerate(train_dataloader,0):\n",
    "#             img0, img1 , label = data\n",
    "#             img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
    "#             optimizer.zero_grad()\n",
    "#             output1,output2 = network(img0,img1)\n",
    "#             loss_contrastive = criterion(output1,output2,label)\n",
    "#             loss_contrastive.backward()\n",
    "#             optimizer.step()    \n",
    "#         print(\"Epoch {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n",
    "#         iteration_number += 10\n",
    "#         counter.append(iteration_number)\n",
    "#         loss.append(loss_contrastive.item())\n",
    "#     plt.show_plot(counter, loss)   \n",
    "#     return network\n",
    "# #set the device to cuda\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = train()\n",
    "# torch.save(model.state_dict(), \"model.pt\")\n",
    "# print(\"Model Saved Successfully\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_net = SiameseNetwork().to(device)\n",
    "criterion = ContrastiveLoss(margin=1.0)\n",
    "optimizer = optim.Adam(siamese_net.parameters(), lr=0.001)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "train_siamese_network(siamese_net, train_loader, criterion, optimizer, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
