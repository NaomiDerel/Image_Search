{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Neural Network Trained with Active Learning Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook details the process of training a Siamese Neural Network designed to create a fine-tuned embedding space of image vectors. This supervised training method uses Contrastive loss between pairs of images to bring embeddings closer or further apart according to their similarity. \n",
    "\n",
    "Due to this expensive labeling domain of similarity between pairs of images, an active learning method is used to find the most informative pairs to label, while minimizing the total number of labels possible in the resources available.\n",
    "\n",
    "The process was done in the following steps:\n",
    "1. Initial small random sample of pairs of images were labeled, from [round0.csv](active_learning_labels/round_0.csv), and divided into training and evaluation. \n",
    "2. The network is trained on the data of the last round only, for 100 epochs. If a previous network was already trained, the training is continued from a saved checkpoint.\n",
    "3. The evaluation of the network is done on the evaluation set as a general guide for the learning capacity of the network. The F1 metric was used due to the unbalanced nature of the dataset.\n",
    "4. The network is used to determine the confidence of the similarity of unlabeled pairs of images. The pairs with the highest confidence were selected for labeling, up to a budget of ~120 pairs.\n",
    "5. Additionally, the network is used to determine the confidence of the similarity on samples automatically tagged with 0, and added those to the labeled set for the next round as well.\n",
    "6. Steps 2 until 5 are repeated, for a total of 4 rounds.\n",
    "\n",
    "The process of the active learning method is logged in this repository. In [active_learning_labels](active_learning_labels) are the labeled pairs of images for each round, and also a blind test set selected independently of the model. In [active_learning_models](active_learning_models) are the checkpoints of the models trained in each round. In [active_learning_results](active_learning_logs) are the logs of the training and evaluation of the models in each round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the current round of active learning:\n",
    "current_round = 3\n",
    "\n",
    "# Load the data paths for the current round:\n",
    "base_path = 'active_learning_labels/'\n",
    "full_data_paths = pd.read_csv(base_path + 'round_' + str(current_round) + '.csv')\n",
    "data_paths = full_data_paths[['image1_path', 'image2_path', 'similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (384, 3) Eval:  (96, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing\n",
    "train_data = data_paths.sample(frac=0.8, random_state=42)\n",
    "eval_data = data_paths.drop(train_data.index)\n",
    "print(\"Train: \", train_data.shape, \"Eval: \", eval_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Computer Vision Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained CLIP model and processor from Hugging Face\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Set up the image transformation pipeline\n",
    "clip_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Define the dataset class\n",
    "augmentations = transforms.Compose([\n",
    "    transforms.RandomApply([transforms.RandomResizedCrop(224)], p=0.3),  # 20% chance of random resized crop\n",
    "    transforms.RandomApply([transforms.RandomHorizontalFlip()], p=0.3),  # 20% chance of horizontal flip\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)], p=0.3),  # 20% chance of color jitter\n",
    "    transforms.ToTensor(),  # Always apply ToTensor\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSimilarityDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class for loading and processing image pairs for similarity tasks.\n",
    "    Attributes:\n",
    "        dataframe (pd.DataFrame): DataFrame containing image paths and similarity scores.\n",
    "        transform (callable, optional): A function/transform to apply to the images.\n",
    "        augmentations (callable, optional): A function/transform to apply augmentations to the images.\n",
    "        master_path (str): The base path to prepend to image paths.\n",
    "    Methods:\n",
    "        __len__():\n",
    "            Returns the number of samples in the dataset.\n",
    "        __getitem__(idx):\n",
    "            Loads and processes the image pair at the given index.\n",
    "            Args:\n",
    "                idx (int): Index of the sample to retrieve.\n",
    "            Returns:\n",
    "                tuple: A tuple containing:\n",
    "                    - image1_path (str): Path to the first image.\n",
    "                    - image2_path (str): Path to the second image.\n",
    "                    - image1_features (torch.Tensor): CLIP features of the first image.\n",
    "                    - image2_features (torch.Tensor): CLIP features of the second image.\n",
    "                    - label (torch.Tensor): Similarity label (1 for similar, 0 for dissimilar).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, transform=clip_transform, augmentations=None):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform\n",
    "        self.augmentations = augmentations\n",
    "        self.master_path = ''\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load images from the paths\n",
    "        image1_path = self.master_path + self.data.iloc[idx, 0].strip(\"()\")\n",
    "        image2_path = self.master_path + self.data.iloc[idx, 1].strip(\"()\")\n",
    "        \n",
    "        # Load images\n",
    "        image1 = Image.open(image1_path).convert(\"RGB\")\n",
    "        image2 = Image.open(image2_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply augmentations if provided\n",
    "        # if self.augmentations:\n",
    "        #     image1 = self.augmentations(image1)\n",
    "        #     image2 = self.augmentations(image2)\n",
    "\n",
    "        # Apply CLIP transforms if provided (transforms should convert to tensor)\n",
    "        if self.transform:\n",
    "            image1 = self.transform(image1)  # Apply transforms including ToTensor\n",
    "            image2 = self.transform(image2)\n",
    "\n",
    "        # Get image features using CLIP\n",
    "        images_features = []\n",
    "        for img in [image1, image2]:\n",
    "            image_tensor = img.unsqueeze(0)  # Add batch dimension for processing\n",
    "            inputs = processor(images=image_tensor, return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                image_features = model.get_image_features(**inputs)\n",
    "            images_features.append(image_features.squeeze())  # Ensure it's a 512-dimensional tensor\n",
    "\n",
    "        # Get similarity score and label (1 for similar, 0 for dissimilar)\n",
    "        similarity = self.data.iloc[idx, 2]\n",
    "        label = 0 if similarity < 3 else 1\n",
    "        \n",
    "        return image1_path, image2_path, images_features[0], images_features[1], torch.tensor(label, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set up device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = ImageSimilarityDataset(train_data, transform=clip_transform, augmentations=None)\n",
    "eval_dataset = ImageSimilarityDataset(eval_data, transform=clip_transform, augmentations=None)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    A Siamese Network for comparing two inputs.\n",
    "    This network processes two input tensors through identical subnetworks and outputs their respective embeddings.\n",
    "    Methods\n",
    "    -------\n",
    "    __init__():\n",
    "        Initializes the Siamese Network with fully connected layers and ReLU activation.\n",
    "    forward_one(x):\n",
    "        Processes a single input tensor through the network to obtain its embedding.\n",
    "    forward(input1, input2):\n",
    "        Processes two input tensors through the network and returns their embeddings.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        A single input tensor to be processed by the network.\n",
    "    input1 : torch.Tensor\n",
    "        The first input tensor to be compared.\n",
    "    input2 : torch.Tensor\n",
    "        The second input tensor to be compared.\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        The embedding of the input tensor from forward_one.\n",
    "    tuple of torch.Tensor\n",
    "        The embeddings of the two input tensors from forward.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        # self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)  # Keep larger dimension here\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        # x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x) \n",
    "        return x\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_one(input1)\n",
    "        output2 = self.forward_one(input2)\n",
    "        return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive Loss Module.\n",
    "    This module computes the contrastive loss, which is used to train models for tasks such as \n",
    "    metric learning. The loss encourages the model to output similar \n",
    "    embeddings for similar inputs and dissimilar embeddings for dissimilar inputs.\n",
    "    Args:\n",
    "        margin (float, optional): The margin value for dissimilar pairs. Default is 1.0.\n",
    "    Methods:\n",
    "        forward(x0, x1, y):\n",
    "            Computes the contrastive loss between two input tensors.\n",
    "            Args:\n",
    "                x0 (torch.Tensor): The first input tensor.\n",
    "                x1 (torch.Tensor): The second input tensor.\n",
    "                y (torch.Tensor): The binary labels indicating whether the pairs are similar (1) or dissimilar (0).\n",
    "            Returns:\n",
    "                torch.Tensor: The computed contrastive loss.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x0, x1, y):\n",
    "        label = y # ensure binary labels\n",
    "        euclidean_distance = nn.functional.pairwise_distance(x0, x1)\n",
    "        loss_contrastive = torch.mean((label) * torch.pow(euclidean_distance, 2) + # similar\n",
    "                                (1 - label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)) # dissimilar\n",
    "        return loss_contrastive\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_siamese_network(model, train_loader, eval_loader, criterion, optimizer, num_epochs):\n",
    "    \"\"\"\n",
    "    Trains a Siamese network model with Contrastive Loss and returns the best model based on F1 score.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The Siamese network model to be trained.\n",
    "        train_loader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
    "        eval_loader (torch.utils.data.DataLoader): DataLoader for the evaluation dataset.\n",
    "        criterion (callable): Loss function to be used.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer for updating the model parameters.\n",
    "        num_epochs (int): Number of epochs to train the model.\n",
    "    Returns:\n",
    "        tuple: A tuple containing the trained model and the state dictionary of the best model based on F1 score.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    max_f1_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        tp, fp, tn, fn = 0, 0, 0, 0\n",
    "        \n",
    "        # Iterate over the training data\n",
    "        for i, (img1_path, img2_path, img1, img2, labels) in tqdm(enumerate(train_loader)):\n",
    "            # Move tensors to the appropriate device\n",
    "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output1, output2 = model(img1, img2)\n",
    "            loss = criterion(output1, output2, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Predictions\n",
    "            dist = F.pairwise_distance(output1, output2)\n",
    "            predicted = (dist < 1.0).float() # margin of 1.0\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # F1 score\n",
    "            tp += ((predicted == 1) & (labels == 1)).sum().item()\n",
    "            fp += ((predicted == 1) & (labels == 0)).sum().item()\n",
    "            tn += ((predicted == 0) & (labels == 0)).sum().item()\n",
    "            fn += ((predicted == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "        f1 = 2 * tp / (2 * tp + fp + fn)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}, Train Accuracy: {correct / len(train_loader.dataset):.2f}, F1 Score: {f1:.2f}\")\n",
    "        \n",
    "        # Save the model with the best F1 score\n",
    "        if f1 >= max_f1_score:\n",
    "            max_f1_score = f1\n",
    "            best_model = model.state_dict()\n",
    "            print(\"Best model updated\")\n",
    "        \n",
    "        # Evaluate the model\n",
    "        # if (epoch + 1) % 5 == 0:\n",
    "        #     model.eval()\n",
    "        #     correct = 0\n",
    "        #     with torch.no_grad():\n",
    "        #         for img1_path, img2_path, img1, img2, labels in eval_loader:\n",
    "        #             img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "        #             output1, output2 = model(img1, img2)\n",
    "        #             dist = F.pairwise_distance(output1, output2)\n",
    "        #             predicted = (dist < 1.0).float()\n",
    "        #             correct += (predicted == labels).sum().item()\n",
    "        #     eval_acc = correct / len(eval_loader.dataset)\n",
    "        #     print(f\"Evaluation Accuracy: {eval_acc:.2f}\")\n",
    "\n",
    "        #     # Save the model with the best evaluation accuracy\n",
    "        #     if eval_acc >= max_acc:\n",
    "        #         max_acc = eval_acc\n",
    "        #         best_model = model.state_dict()\n",
    "        #         print(\"Best model updated\")\n",
    "\n",
    "    return model, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model:\n",
    "siamese_net = SiameseNetwork().to(device)\n",
    "criterion = ContrastiveLoss(margin=1.0)\n",
    "optimizer = optim.Adam(siamese_net.parameters(), lr=0.01)\n",
    "num_epochs = 50\n",
    "\n",
    "# Start from last trained model:\n",
    "siamese_net.load_state_dict(torch.load('active_learning_models/net_round3_2_best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "48it [01:44,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.1484, Train Accuracy: 0.79, F1 Score: 0.13\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:05,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Loss: 0.1313, Train Accuracy: 0.74, F1 Score: 0.26\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:04,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Loss: 0.1042, Train Accuracy: 0.77, F1 Score: 0.29\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:01,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Loss: 0.0710, Train Accuracy: 0.73, F1 Score: 0.30\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:03,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Loss: 0.0545, Train Accuracy: 0.78, F1 Score: 0.38\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Loss: 0.0481, Train Accuracy: 0.82, F1 Score: 0.40\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:03,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Loss: 0.0706, Train Accuracy: 0.77, F1 Score: 0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:03,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Loss: 0.0528, Train Accuracy: 0.76, F1 Score: 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:03,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Loss: 0.0480, Train Accuracy: 0.82, F1 Score: 0.41\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:03,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.0554, Train Accuracy: 0.81, F1 Score: 0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Loss: 0.0581, Train Accuracy: 0.84, F1 Score: 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Loss: 0.0343, Train Accuracy: 0.85, F1 Score: 0.45\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Loss: 0.0422, Train Accuracy: 0.83, F1 Score: 0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:03,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Loss: 0.0375, Train Accuracy: 0.83, F1 Score: 0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Loss: 0.0280, Train Accuracy: 0.87, F1 Score: 0.51\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Loss: 0.0243, Train Accuracy: 0.88, F1 Score: 0.55\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:03,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Loss: 0.0327, Train Accuracy: 0.88, F1 Score: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:03,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Loss: 0.0397, Train Accuracy: 0.89, F1 Score: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:04,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Loss: 0.0242, Train Accuracy: 0.90, F1 Score: 0.59\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Loss: 0.0365, Train Accuracy: 0.86, F1 Score: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Loss: 0.0475, Train Accuracy: 0.89, F1 Score: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Loss: 0.0809, Train Accuracy: 0.90, F1 Score: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Loss: 0.0631, Train Accuracy: 0.88, F1 Score: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Loss: 0.1349, Train Accuracy: 0.91, F1 Score: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Loss: 0.4100, Train Accuracy: 0.90, F1 Score: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:03,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Loss: 6.9312, Train Accuracy: 0.92, F1 Score: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Loss: 14.5368, Train Accuracy: 0.93, F1 Score: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:01,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Loss: 3.5775, Train Accuracy: 0.93, F1 Score: 0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Loss: 0.2800, Train Accuracy: 0.93, F1 Score: 0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Loss: 0.0604, Train Accuracy: 0.88, F1 Score: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:01,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Loss: 0.0376, Train Accuracy: 0.86, F1 Score: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:01,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Loss: 0.0328, Train Accuracy: 0.87, F1 Score: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:01,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Loss: 0.0267, Train Accuracy: 0.87, F1 Score: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:01,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Loss: 0.0236, Train Accuracy: 0.88, F1 Score: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:03,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Loss: 0.0185, Train Accuracy: 0.88, F1 Score: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Loss: 0.0160, Train Accuracy: 0.88, F1 Score: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Loss: 0.0141, Train Accuracy: 0.90, F1 Score: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Loss: 0.0130, Train Accuracy: 0.89, F1 Score: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:01,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Loss: 0.0122, Train Accuracy: 0.90, F1 Score: 0.60\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Loss: 0.0091, Train Accuracy: 0.91, F1 Score: 0.62\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:03,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Loss: 0.0095, Train Accuracy: 0.90, F1 Score: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Loss: 0.0085, Train Accuracy: 0.91, F1 Score: 0.62\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Loss: 0.0076, Train Accuracy: 0.90, F1 Score: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:04,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Loss: 0.0075, Train Accuracy: 0.91, F1 Score: 0.62\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Loss: 0.0071, Train Accuracy: 0.91, F1 Score: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:01,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Loss: 0.0061, Train Accuracy: 0.91, F1 Score: 0.63\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:02,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Loss: 0.0063, Train Accuracy: 0.91, F1 Score: 0.63\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:03,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Loss: 0.0059, Train Accuracy: 0.91, F1 Score: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:01,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Loss: 0.0051, Train Accuracy: 0.92, F1 Score: 0.65\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:01,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 0.0051, Train Accuracy: 0.93, F1 Score: 0.67\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model, best_f1_trained_model = train_siamese_network(siamese_net, train_loader, eval_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "save_path = 'active_learning_models/net_round4.pth'\n",
    "\n",
    "if os.path.exists(save_path):\n",
    "    print(\"Model already exists\")\n",
    "else:\n",
    "    torch.save(best_f1_trained_model, 'active_learning_models/net_round4_best.pth')\n",
    "    torch.save(trained_model.state_dict(), save_path)\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7280/1548265267.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load('active_learning_models/net_round4_best.pth', map_location=torch.device(device)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model\n",
    "best_model = SiameseNetwork().to(device)\n",
    "best_model.load_state_dict(torch.load('active_learning_models/net_round4_best.pth', map_location=torch.device(device)))\n",
    "\n",
    "# final_model = SiameseNetwork().to(device)\n",
    "# final_model.load_state_dict(torch.load('active_learning_models/net_round3_2_final.pth', map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_siamese_network(model, test_loader, loader_name):\n",
    "    \"\"\"\n",
    "    Evaluates a Siamese network on a given test dataset.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The Siamese network model to be evaluated.\n",
    "        test_loader (torch.utils.data.DataLoader): DataLoader for the test dataset.\n",
    "        loader_name (str): Name of the test dataset loader, used for printing results.\n",
    "    Returns:\n",
    "        None\n",
    "    This function performs the following steps:\n",
    "        1. Sets the model to evaluation mode.\n",
    "        2. Iterates over the test dataset and performs a forward pass to get the outputs.\n",
    "        3. Calculates the Euclidean distance between the outputs of the Siamese network.\n",
    "        4. Determines predictions based on the distance.\n",
    "        5. Computes the accuracy of the model on the test dataset.\n",
    "        6. Computes the F1 score of the model on the test dataset.\n",
    "        7. Generates and displays a confusion matrix heatmap.\n",
    "    Note:\n",
    "        This function assumes that the model and data are compatible with the device (CPU/GPU) being used.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the test data\n",
    "        for i, (img1_path, img2_path, img1, img2, labels) in enumerate(test_loader):\n",
    "            # Move tensors to the appropriate device\n",
    "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output1, output2 = model(img1, img2)\n",
    "\n",
    "            # Calculate the euclidean distance between the outputs\n",
    "            dist = F.pairwise_distance(output1, output2)\n",
    "\n",
    "            # Get predictions\n",
    "            predicted = (dist < 1.0).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_labels.extend(labels)\n",
    "            all_predictions.extend(predicted)\n",
    "\n",
    "    # accuracy:\n",
    "    accuracy = correct / total\n",
    "    print(f\"{loader_name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # f1 score:\n",
    "    all_labels = [label.cpu().numpy() for label in all_labels]\n",
    "    all_predictions = [prediction.cpu().numpy() for prediction in all_predictions]\n",
    "    f1 = f1_score(all_labels, all_predictions)\n",
    "    print(f\"{loader_name} F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # confusion matrix:\n",
    "    matrix = confusion_matrix(all_labels, all_predictions)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(matrix, annot=True, fmt='g', cmap='Blues')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9167\n",
      "Train F1 Score: 0.6364\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Accuracy: 0.7292\n",
      "Eval F1 Score: 0.1875\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_siamese_network(best_model, train_loader, \"Train\")\n",
    "test_siamese_network(best_model, eval_loader, \"Eval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model - added in final steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('active_learning_labels/blind_test.csv')\n",
    "test_data = test_data[['image1_path', 'image2_path', 'similarity']]\n",
    "\n",
    "test_dataset = ImageSimilarityDataset(test_data, transform=clip_transform, augmentations=None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8767\n",
      "Test F1 Score: 0.1395\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_siamese_network(best_model, test_loader, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabeled rows:  (33188, 5)\n"
     ]
    }
   ],
   "source": [
    "# Find the unlabeled data for the next round:\n",
    "path_data_pool = \"datasets/house_styles/sampled_paired_labels_shuffled.csv\"\n",
    "data_pool = pd.read_csv(path_data_pool)\n",
    "unlabeled_rows = data_pool[data_pool['similarity'].isna()]\n",
    "print(\"Unlabeled rows: \", unlabeled_rows.shape)\n",
    "\n",
    "# Sample 10,000 rows for the next round for feasible runtime:\n",
    "unlabeled_rows = unlabeled_rows[['image1_path', 'image2_path', 'similarity']].sample(10000)\n",
    "# Create the dataset for the next round:\n",
    "unlabeled_dataset = ImageSimilarityDataset(unlabeled_rows, transform=clip_transform)\n",
    "data_loader = DataLoader(unlabeled_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_learning_confident_samples(model, dataloader, margin=1.0, budget=120):\n",
    "    \"\"\"\n",
    "    Selects the least confident samples from a dataloader using an active learning strategy.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model used for generating embeddings.\n",
    "        dataloader (torch.utils.data.DataLoader): DataLoader providing batches of image pairs and labels.\n",
    "        margin (float, optional): The margin used to calculate confidence scores. Default is 1.0.\n",
    "        budget (int, optional): The number of least confident samples to return. Default is 120.\n",
    "    Returns:\n",
    "        list: A list of tuples containing the paths of the image pairs, their pairwise distance, \n",
    "              and their confidence score. The list is sorted in ascending order of confidence score.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    least_confident_samples = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the data loader\n",
    "        for img1_path, img2_path, img1, img2, labels in tqdm(dataloader):\n",
    "            # Move tensors to the appropriate device\n",
    "            img1, img2, label = img1.to(device), img2.to(device), labels.to(device)\n",
    "\n",
    "            # Get the model outputs for both images\n",
    "            output1, output2 = model(img1, img2)\n",
    "            \n",
    "            # Calculate pairwise distance\n",
    "            distances = F.pairwise_distance(output1, output2)\n",
    "            \n",
    "            # Calculate confidence score (distance from the margin)\n",
    "            confidence_scores = torch.abs(distances - margin)\n",
    "\n",
    "            # Collect the least confident samples (small confidence score means high uncertainty)\n",
    "            for i in range(len(confidence_scores)):\n",
    "                least_confident_samples.append((img1_path[i], img2_path[i], distances[i].item(), confidence_scores[i].item()))\n",
    "\n",
    "    # Sort samples by confidence score (ascending, to get least confident samples)\n",
    "    least_confident_samples.sort(key=lambda x: x[3])\n",
    "\n",
    "    # Return the top_k least confident samples\n",
    "    return least_confident_samples[:budget]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_confident_samples = active_learning_confident_samples(trained_model, data_loader, margin=1.0, budget=120)\n",
    "# print(least_confident_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find data labeled as 0 automatically for the next round:\n",
    "zero_rows = data_pool[data_pool['similarity'] == 0]\n",
    "zero_rows = zero_rows[['image1_path', 'image2_path', 'similarity']].sample(10000)\n",
    "zero_dataset = ImageSimilarityDataset(zero_rows, transform=clip_transform)\n",
    "zero_data_loader = DataLoader(zero_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_confident_zero = active_learning_confident_samples(trained_model, zero_data_loader, margin=1.0, budget=360)\n",
    "# print(least_confident_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the active learning samples to be labeled without a similarity score:\n",
    "least_confident_samples_df = pd.DataFrame(least_confident_samples, columns=['image1_path', 'image2_path', 'distance', 'confidence'])\n",
    "least_confident_samples_df['similarity'] = None\n",
    "\n",
    "# Save the active learning samples with a similarity score of 0:\n",
    "zero_samples_df = pd.DataFrame(least_confident_zero, columns=['image1_path', 'image2_path', 'distance', 'confidence'])\n",
    "zero_samples_df['similarity'] = float(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a csv for easy labeling:\n",
    "\n",
    "active_learning_df = pd.concat([least_confident_samples_df, zero_samples_df], ignore_index=True)\n",
    "# add image names:\n",
    "active_learning_df['image1'] = active_learning_df['image1_path'].apply(lambda x: x.split('/')[-1])\n",
    "active_learning_df['image2'] = active_learning_df['image2_path'].apply(lambda x: x.split('/')[-1])\n",
    "# make paths be surrounded by parentheses:\n",
    "active_learning_df['image1_path'] = active_learning_df['image1_path'].apply(lambda x: '(' + x + ')')\n",
    "active_learning_df['image2_path'] = active_learning_df['image2_path'].apply(lambda x: '(' + x + ')')\n",
    "# shorten distance and confidence:\n",
    "active_learning_df['distance'] = active_learning_df['distance'].apply(lambda x: round(x, 4))\n",
    "active_learning_df['confidence'] = active_learning_df['confidence'].apply(lambda x: round(x, 4))\n",
    "\n",
    "# reorder columns:\n",
    "active_learning_df = active_learning_df[['image1', 'image1_path', 'image2', 'image2_path', 'distance', 'confidence', 'similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist\n",
      "File saved\n"
     ]
    }
   ],
   "source": [
    "# Save the active learning samples to a csv file:\n",
    "result_active_learning_path = 'active_learning_labels/round_2.csv'\n",
    "\n",
    "if os.path.exists(result_active_learning_path):\n",
    "    print(\"File exists\")\n",
    "else:\n",
    "    print(\"File does not exist\")\n",
    "    active_learning_df.to_csv(result_active_learning_path, index=False)\n",
    "    print(\"File saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
