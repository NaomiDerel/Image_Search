{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - Similiarity Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook details the process of choosing the similarity function that determines the images that are similar to a given image.\n",
    "The implementation of the network is based on the Siamese network implementation. This class of networks is known to be more robust to class imbalance, so it fits the data on which we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import CLIPModel, CLIPProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         image1_path  \\\n",
      "0  (datasets/house_styles/all_images/001_d2c7428a...   \n",
      "1  (datasets/house_styles/all_images/453_d7b5d246...   \n",
      "2  (datasets/house_styles/all_images/116_32f01ef6...   \n",
      "3  (datasets/house_styles/all_images/301_b73b9663...   \n",
      "4  (datasets/house_styles/all_images/042_06b56791...   \n",
      "\n",
      "                                         image2_path  similarity  \n",
      "0  (datasets/house_styles/all_images/366_08eff319...         3.0  \n",
      "1  (datasets/house_styles/all_images/122_e44a0cb3...         0.0  \n",
      "2  (datasets/house_styles/all_images/174_55a7b3f9...         0.0  \n",
      "3  (datasets/house_styles/all_images/116_32f01ef6...         0.0  \n",
      "4  (datasets/house_styles/all_images/069_d3bedc1f...         1.0  \n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "base_path = 'active_learning_labels/'\n",
    "full_data_paths = pd.read_csv(base_path + 'round_0.csv')\n",
    "\n",
    "current_round = 1\n",
    "\n",
    "if current_round > 0:\n",
    "    for i in range(1, current_round):\n",
    "        path = base_path + 'round_' + str(i) + '.csv'\n",
    "        data = pd.read_csv(path)\n",
    "        full_data_paths = pd.concat([full_data_paths, data], ignore_index=True)\n",
    "\n",
    "data_paths = full_data_paths[['image1_path', 'image2_path', 'similarity']]\n",
    "\n",
    "print(data_paths.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (566, 3) Eval:  (142, 3)\n"
     ]
    }
   ],
   "source": [
    "# split the data into training and testing\n",
    "train_data = data_paths.sample(frac=0.8, random_state=42)\n",
    "eval_data = data_paths.drop(train_data.index)\n",
    "\n",
    "print(\"Train: \", train_data.shape, \"Eval: \", eval_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Computer Vision Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained CLIP model and processor from Hugging Face\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Set up the image transformation pipeline\n",
    "clip_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "# Define the dataset class\n",
    "augmentations = transforms.Compose([\n",
    "    transforms.RandomApply([transforms.RandomResizedCrop(224)], p=0.2),  # 20% chance of random resized crop\n",
    "    transforms.RandomApply([transforms.RandomHorizontalFlip()], p=0.2),  # 20% chance of horizontal flip\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)], p=0.2),  # 20% chance of color jitter\n",
    "    transforms.ToTensor(),  # Always apply ToTensor\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSimilarityDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=clip_transform, augmentations=None):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform\n",
    "        self.augmentations = augmentations\n",
    "        self.master_path = ''\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load images from the paths\n",
    "        image1_path = self.master_path + self.data.iloc[idx, 0].strip(\"()\")\n",
    "        image2_path = self.master_path + self.data.iloc[idx, 1].strip(\"()\")\n",
    "        \n",
    "        # Load images\n",
    "        image1 = Image.open(image1_path).convert(\"RGB\")\n",
    "        image2 = Image.open(image2_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply augmentations if provided\n",
    "        if self.augmentations:\n",
    "            image1 = self.augmentations(image1)\n",
    "            image2 = self.augmentations(image2)\n",
    "\n",
    "        # # CLIP:\n",
    "        # images_features = []\n",
    "        # for img in [image1, image2]:\n",
    "        #     image_tensor = self.transform(img).unsqueeze(0)\n",
    "        #     inputs = processor(images=image_tensor, return_tensors=\"pt\")\n",
    "        #     with torch.no_grad():\n",
    "        #         image_features = model.get_image_features(**inputs)\n",
    "        #         #images_features.append(image_features.numpy().flatten())\n",
    "        #     images_features.append(image_features.squeeze())  # Ensure it's a 512-dimensional tensor\n",
    "\n",
    "        \n",
    "        # Apply CLIP transforms if provided (transforms should convert to tensor)\n",
    "        if self.transform:\n",
    "            image1 = self.transform(image1)  # Apply transforms including ToTensor\n",
    "            image2 = self.transform(image2)\n",
    "\n",
    "        # Get image features using CLIP\n",
    "        images_features = []\n",
    "        for img in [image1, image2]:\n",
    "            image_tensor = img.unsqueeze(0)  # Add batch dimension for processing\n",
    "            inputs = processor(images=image_tensor, return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                image_features = model.get_image_features(**inputs)\n",
    "            images_features.append(image_features.squeeze())  # Ensure it's a 512-dimensional tensor\n",
    "\n",
    "        # Get similarity score and label (1 for similar, 0 for dissimilar)\n",
    "        similarity = self.data.iloc[idx, 2]\n",
    "        label = 0 if similarity < 3 else 1\n",
    "        \n",
    "        return image1_path, image2_path, images_features[0], images_features[1], torch.tensor(label, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = ImageSimilarityDataset(train_data, transform=clip_transform, augmentations=None)\n",
    "eval_dataset = ImageSimilarityDataset(eval_data, transform=clip_transform, augmentations=None)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        # self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)  # Keep larger dimension here\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        # x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x) \n",
    "        return x\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_one(input1)\n",
    "        output2 = self.forward_one(input2)\n",
    "        return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SiameseNetwork(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SiameseNetwork, self).__init__()\n",
    "#         # Using fully connected layers to process 512-dimensional CLIP features\n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Linear(512, 256),  # First layer to reduce dimensions\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(p=0.5),\n",
    "#             nn.Linear(256, 128),  # Second layer\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(128, 2)     # Output layer with 2 units (for similarity comparison)\n",
    "#         )\n",
    "\n",
    "#     def forward_once(self, x):\n",
    "#         # Forward pass through fully connected layers\n",
    "#         return self.fc1(x)\n",
    "\n",
    "#     def forward(self, input1, input2):\n",
    "#         # Forward pass for both inputs\n",
    "#         output1 = self.forward_once(input1)\n",
    "#         output2 = self.forward_once(input2)\n",
    "#         return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SiameseNetwork(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SiameseNetwork, self).__init__()\n",
    "#         # Use fully connected layers for processing 512-dimensional CLIP features\n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Linear(512, 256),  # Assuming CLIP outputs 512-dimensional features\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(p=0.5),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(128, 2)\n",
    "#         )\n",
    "\n",
    "#     def forward_once(self, x):\n",
    "#         # Forward pass through fully connected layers\n",
    "#         x = self.fc1(x)\n",
    "#         return x\n",
    "\n",
    "#     def forward(self, input1, input2):\n",
    "#         # Forward pass of input 1\n",
    "#         output1 = self.forward_once(input1)\n",
    "#         # Forward pass of input 2\n",
    "#         output2 = self.forward_once(input2)\n",
    "#         return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SiameseNetwork(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super(SiameseNetwork, self).__init__()\n",
    "#         # Setting up the Sequential of CNN Layers\n",
    "#         self.cnn1 = nn.Sequential(\n",
    "#             nn.Conv2d(3, 96, kernel_size=11, stride=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2),\n",
    "#             nn.MaxPool2d(3, stride=2),\n",
    "#             nn.Dropout2d(p=0.3),\n",
    "            \n",
    "#             nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2),\n",
    "#             nn.MaxPool2d(3, stride=2),\n",
    "#             nn.Dropout2d(p=0.3),\n",
    "\n",
    "#             nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            \n",
    "#             nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(3, stride=2),\n",
    "#             nn.Dropout2d(p=0.3),\n",
    "#         )\n",
    "        \n",
    "#         # Adaptive pooling layer to ensure the output size is consistent\n",
    "#         self.adaptive_pool = nn.AdaptiveAvgPool2d((6, 6))  # Adjust pooling size to handle dynamic input\n",
    "        \n",
    "#         # Defining the fully connected layers\n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Linear(256 * 6 * 6, 1024),  # Input size adjusted for adaptive pooling\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(p=0.5),\n",
    "            \n",
    "#             nn.Linear(1024, 128),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            \n",
    "#             nn.Linear(128, 2)\n",
    "#         )\n",
    "        \n",
    "#     def forward_once(self, x):\n",
    "#         # Forward pass \n",
    "#         x = self.cnn1(x)\n",
    "#         x = self.adaptive_pool(x)  # Adaptive pooling to standardize the feature map size\n",
    "#         x = x.view(x.size(0), -1)  # Flatten the feature map\n",
    "#         x = self.fc1(x)\n",
    "#         return x\n",
    "\n",
    "#     def forward(self, input1, input2):\n",
    "#         # Forward pass of input 1\n",
    "#         output1 = self.forward_once(input1)\n",
    "#         # Forward pass of input 2\n",
    "#         output2 = self.forward_once(input2)\n",
    "#         return output1, output2\n",
    "\n",
    "# # class SiameseNetwork(nn.Module):\n",
    "    \n",
    "# #     def __init__(self):\n",
    "# #         super(SiameseNetwork, self).__init__()\n",
    "# #         # Setting up the Sequential of CNN Layers\n",
    "# #         self.cnn1 = nn.Sequential(\n",
    "# #             nn.Conv2d(3, 96, kernel_size=11, stride=1),  # Adjusted for RGB input\n",
    "# #             nn.ReLU(inplace=True),\n",
    "# #             nn.MaxPool2d(3, stride=2),\n",
    "            \n",
    "# #             nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "# #             nn.ReLU(inplace=True),\n",
    "# #             nn.MaxPool2d(3, stride=2),\n",
    "# #             nn.Dropout2d(p=0.3),\n",
    "\n",
    "# #             nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "# #             nn.ReLU(inplace=True),\n",
    "            \n",
    "# #             nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "# #             nn.ReLU(inplace=True),\n",
    "# #             nn.MaxPool2d(3, stride=2),\n",
    "# #             nn.Dropout2d(p=0.3),\n",
    "# #         )\n",
    "        \n",
    "# #         # Adaptive pooling layer to ensure the output size is consistent\n",
    "# #         self.adaptive_pool = nn.AdaptiveAvgPool2d((6, 6))  # Adjust pooling size to handle dynamic input\n",
    "        \n",
    "# #         # Defining the fully connected layers\n",
    "# #         self.fc1 = nn.Sequential(\n",
    "# #             nn.Linear(256 * 6 * 6, 1024),  # Input size adjusted for adaptive pooling\n",
    "# #             nn.ReLU(inplace=True),\n",
    "# #             nn.Dropout(p=0.5),\n",
    "            \n",
    "# #             nn.Linear(1024, 128),\n",
    "# #             nn.ReLU(inplace=True),\n",
    "            \n",
    "# #             nn.Linear(128, 2)\n",
    "# #         )\n",
    "        \n",
    "# #     def forward_once(self, x):\n",
    "# #         # Forward pass \n",
    "# #         x = self.cnn1(x)\n",
    "# #         x = self.adaptive_pool(x)  # Adaptive pooling to standardize the feature map size\n",
    "# #         x = x.view(x.size(0), -1)  # Flatten the feature map\n",
    "#     #     x = self.fc1(x)\n",
    "#     #     return x\n",
    "\n",
    "#     # def forward(self, input1, input2):\n",
    "#     #     # Forward pass of input 1\n",
    "#     #     output1 = self.forward_once(input1)\n",
    "#     #     # Forward pass of input 2\n",
    "#     #     output2 = self.forward_once(input2)\n",
    "#     #     return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SmallSiameseNetwork(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super(SmallSiameseNetwork, self).__init__()\n",
    "#         # Setting up a smaller CNN\n",
    "#         self.cnn1 = nn.Sequential(\n",
    "#             nn.Conv2d(3, 32, kernel_size=7, stride=1, padding=1),  # Fewer filters, smaller kernel size\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(2, stride=2),  # Max pooling with smaller stride to reduce spatial dimensions\n",
    "#             nn.Dropout2d(p=0.2),  # Reduced dropout rate\n",
    "            \n",
    "#             nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=1),  # Fewer filters\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(2, stride=2),  # Smaller max-pooling\n",
    "#             nn.Dropout2d(p=0.2),\n",
    "\n",
    "#             # nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  # Fewer filters\n",
    "#             # nn.ReLU(inplace=True),\n",
    "#             # nn.MaxPool2d(2, stride=2),\n",
    "#             # nn.Dropout2d(p=0.2),\n",
    "#         )\n",
    "        \n",
    "#         # Adaptive pooling layer to standardize output size (reduce to 3x3)\n",
    "#         self.adaptive_pool = nn.AdaptiveAvgPool2d((3, 3))  # Smaller output size (3x3)\n",
    "        \n",
    "#         # Defining smaller fully connected layers\n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Linear(64 * 3 * 3, 128),  # Reduced size based on new feature map size\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(p=0.4),  # Keep some dropout for regularization\n",
    "            \n",
    "#             nn.Linear(128, 64),  # Smaller fully connected layer\n",
    "#             nn.ReLU(inplace=True),\n",
    "            \n",
    "#             nn.Linear(64, 2)  # Output layer remains the same\n",
    "#         )\n",
    "        \n",
    "#     def forward_once(self, x):\n",
    "#         # Forward pass \n",
    "#         x = self.cnn1(x)\n",
    "#         x = self.adaptive_pool(x)  # Adaptive pooling to standardize the feature map size\n",
    "#         x = x.view(x.size(0), -1)  # Flatten the feature map\n",
    "#         x = self.fc1(x)\n",
    "#         return x\n",
    "\n",
    "#     def forward(self, input1, input2):\n",
    "#         # Forward pass of input 1\n",
    "#         output1 = self.forward_once(input1)\n",
    "#         # Forward pass of input 2\n",
    "#         output2 = self.forward_once(input2)\n",
    "#         return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on:\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x0, x1, y):\n",
    "        ### Binary:\n",
    "        # euclidian distance\n",
    "        # diff = x0 - x1\n",
    "        # dist_sq = torch.sum(torch.pow(diff, 2), 1)\n",
    "        # if torch.any(dist_sq < 0):\n",
    "        #     print('the value of dist_sq is negative: ' + dist_sq)\n",
    "        # # dist = torch.sqrt(torch.abs(dist_sq))\n",
    "        # dist = torch.sqrt(dist_sq + 1e-6)\n",
    "        # mdist = self.margin - dist\n",
    "        # dist = torch.clamp(mdist, min=0.0)\n",
    "        # loss = y * dist_sq + (1 - y) * torch.pow(dist, 2)\n",
    "        # loss = torch.sum(loss) / 2.0 / x0.size()[0]\n",
    "\n",
    "        label = y #binary?\n",
    "        euclidean_distance = nn.functional.pairwise_distance(x0, x1)\n",
    "        loss_contrastive = torch.mean((label) * torch.pow(euclidean_distance, 2) + # similar\n",
    "                                (1 - label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)) # dissimilar\n",
    "        return loss_contrastive\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_siamese_network(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    min_loss = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        \n",
    "        for i, (img1_path, img2_path, img1, img2, labels) in tqdm(enumerate(train_loader)):\n",
    "            # Move tensors to the appropriate device\n",
    "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output1, output2 = model(img1, img2)\n",
    "            loss = criterion(output1, output2, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Accuracy\n",
    "            dist = F.pairwise_distance(output1, output2)\n",
    "            predicted = (dist < 1.0).float()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Print statistics\n",
    "            # if (i + 1) % 10 == 0:  # Print every 5 batches\n",
    "            #     print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 10:.4f}\")\n",
    "            #     running_loss = 0.0\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}, Accuracy: {correct / len(train_loader.dataset):.2f}\")\n",
    "        \n",
    "        # Save the model with the best loss\n",
    "        if running_loss < min_loss:\n",
    "            min_loss = running_loss\n",
    "            best_model = model.state_dict()\n",
    "            print(\"Best model updated\") \n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_net = SiameseNetwork().to(device)\n",
    "criterion = ContrastiveLoss(margin=1.0)\n",
    "optimizer = optim.Adam(siamese_net.parameters(), lr=0.01)\n",
    "num_epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Loss: 0.3716, Accuracy: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/150], Loss: 0.1815, Accuracy: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/150], Loss: 0.1822, Accuracy: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/150], Loss: 0.1708, Accuracy: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:23,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/150], Loss: 0.4076, Accuracy: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/150], Loss: 7.4820, Accuracy: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/150], Loss: 1.6608, Accuracy: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/150], Loss: 0.1766, Accuracy: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:28,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/150], Loss: 0.1255, Accuracy: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/150], Loss: 0.1246, Accuracy: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/150], Loss: 0.0996, Accuracy: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/150], Loss: 0.0991, Accuracy: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/150], Loss: 0.0920, Accuracy: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/150], Loss: 0.0858, Accuracy: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/150], Loss: 0.0854, Accuracy: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/150], Loss: 0.0799, Accuracy: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/150], Loss: 0.0724, Accuracy: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/150], Loss: 0.0723, Accuracy: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/150], Loss: 0.0694, Accuracy: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/150], Loss: 0.0759, Accuracy: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/150], Loss: 0.0643, Accuracy: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/150], Loss: 0.0780, Accuracy: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/150], Loss: 0.0603, Accuracy: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/150], Loss: 0.0618, Accuracy: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/150], Loss: 0.0529, Accuracy: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/150], Loss: 0.0621, Accuracy: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/150], Loss: 0.0561, Accuracy: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:23,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/150], Loss: 0.0566, Accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/150], Loss: 0.0448, Accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/150], Loss: 0.0507, Accuracy: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/150], Loss: 0.0522, Accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:23,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/150], Loss: 0.0581, Accuracy: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/150], Loss: 0.1164, Accuracy: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/150], Loss: 0.0714, Accuracy: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/150], Loss: 0.0494, Accuracy: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/150], Loss: 0.0465, Accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/150], Loss: 0.0464, Accuracy: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/150], Loss: 0.0411, Accuracy: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/150], Loss: 0.0456, Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/150], Loss: 0.0463, Accuracy: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/150], Loss: 0.0496, Accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/150], Loss: 0.0372, Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/150], Loss: 0.0639, Accuracy: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/150], Loss: 0.0482, Accuracy: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/150], Loss: 0.0838, Accuracy: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/150], Loss: 0.0756, Accuracy: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/150], Loss: 0.0500, Accuracy: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/150], Loss: 0.0385, Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/150], Loss: 0.0423, Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/150], Loss: 0.0444, Accuracy: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/150], Loss: 0.0315, Accuracy: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/150], Loss: 0.0331, Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/150], Loss: 0.0266, Accuracy: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/150], Loss: 0.0293, Accuracy: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/150], Loss: 0.0341, Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/150], Loss: 0.0271, Accuracy: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/150], Loss: 0.0301, Accuracy: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/150], Loss: 0.0440, Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/150], Loss: 0.0424, Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/150], Loss: 0.0410, Accuracy: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/150], Loss: 0.0453, Accuracy: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/150], Loss: 0.0280, Accuracy: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:28,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/150], Loss: 0.0274, Accuracy: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/150], Loss: 0.0310, Accuracy: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:28,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/150], Loss: 0.0327, Accuracy: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/150], Loss: 0.0291, Accuracy: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/150], Loss: 0.0284, Accuracy: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/150], Loss: 0.0268, Accuracy: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:28,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/150], Loss: 0.0326, Accuracy: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/150], Loss: 0.0456, Accuracy: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/150], Loss: 0.0357, Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/150], Loss: 0.0279, Accuracy: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/150], Loss: 0.0291, Accuracy: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/150], Loss: 0.0352, Accuracy: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/150], Loss: 0.0334, Accuracy: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/150], Loss: 0.0278, Accuracy: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/150], Loss: 0.0294, Accuracy: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:28,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/150], Loss: 0.0310, Accuracy: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/150], Loss: 0.0339, Accuracy: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/150], Loss: 0.0392, Accuracy: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/150], Loss: 0.0412, Accuracy: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/150], Loss: 0.0823, Accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/150], Loss: 30.4234, Accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/150], Loss: 52.1366, Accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/150], Loss: 0.8988, Accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/150], Loss: 0.1895, Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/150], Loss: 0.1460, Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/150], Loss: 0.0980, Accuracy: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/150], Loss: 0.0762, Accuracy: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/150], Loss: 0.0608, Accuracy: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/150], Loss: 0.0575, Accuracy: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/150], Loss: 0.0564, Accuracy: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/150], Loss: 0.0449, Accuracy: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/150], Loss: 0.0423, Accuracy: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/150], Loss: 0.0395, Accuracy: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/150], Loss: 0.0441, Accuracy: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:31,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/150], Loss: 0.0387, Accuracy: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/150], Loss: 0.0389, Accuracy: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/150], Loss: 0.0349, Accuracy: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/150], Loss: 0.0330, Accuracy: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/150], Loss: 0.0372, Accuracy: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [102/150], Loss: 0.0354, Accuracy: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [103/150], Loss: 0.0261, Accuracy: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [104/150], Loss: 0.0336, Accuracy: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [105/150], Loss: 0.0252, Accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [106/150], Loss: 0.0203, Accuracy: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107/150], Loss: 0.0182, Accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [108/150], Loss: 0.0173, Accuracy: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [109/150], Loss: 0.0233, Accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [110/150], Loss: 0.0233, Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:22,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [111/150], Loss: 0.0699, Accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [112/150], Loss: 0.0606, Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [113/150], Loss: 0.0499, Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [114/150], Loss: 0.0293, Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [115/150], Loss: 0.0290, Accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [116/150], Loss: 0.0300, Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:28,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [117/150], Loss: 0.0198, Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [118/150], Loss: 0.0161, Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [119/150], Loss: 0.0209, Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/150], Loss: 0.0651, Accuracy: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [121/150], Loss: 0.0649, Accuracy: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [122/150], Loss: 0.0648, Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [123/150], Loss: 0.2402, Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:28,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124/150], Loss: 0.0821, Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [125/150], Loss: 0.0549, Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [126/150], Loss: 0.0197, Accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [127/150], Loss: 0.0142, Accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [128/150], Loss: 0.0162, Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [129/150], Loss: 0.0118, Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [130/150], Loss: 0.0191, Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [131/150], Loss: 0.0170, Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [132/150], Loss: 0.0116, Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [133/150], Loss: 0.0135, Accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [134/150], Loss: 0.0119, Accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [135/150], Loss: 0.0108, Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [136/150], Loss: 0.0227, Accuracy: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [137/150], Loss: 0.0251, Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [138/150], Loss: 0.2540, Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:24,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [139/150], Loss: 0.0247, Accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:23,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [140/150], Loss: 0.0242, Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:25,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [141/150], Loss: 0.0345, Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [142/150], Loss: 0.0799, Accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [143/150], Loss: 0.1248, Accuracy: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [144/150], Loss: 0.0228, Accuracy: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:28,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [145/150], Loss: 0.0191, Accuracy: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:26,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [146/150], Loss: 0.0149, Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [147/150], Loss: 0.0092, Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [148/150], Loss: 0.0088, Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:28,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [149/150], Loss: 0.0102, Accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:27,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [150/150], Loss: 0.0116, Accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_siamese_network(siamese_net, train_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(siamese_net.state_dict(), 'siamese_net_3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "siamese_net.load_state_dict(torch.load('siamese_net.pth'))\n",
    "trained_model = siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 0.7465\n",
      "Test F1 Score: 0.1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def test_siamese_network(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (img1_path, img2_path, img1, img2, labels) in enumerate(test_loader):\n",
    "            # Move tensors to the appropriate device\n",
    "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output1, output2 = model(img1, img2)\n",
    "\n",
    "            # Calculate the euclidean distance between the outputs\n",
    "            dist = F.pairwise_distance(output1, output2)\n",
    "\n",
    "            # Get predictions\n",
    "            predicted = (dist < 1.0).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_labels.extend(labels)\n",
    "            all_predictions.extend(predicted)\n",
    "\n",
    "            # print(f\"Dist: {dist}, Predicted: {predicted}, Actual: {labels}\")\n",
    "\n",
    "            # if i == 10:\n",
    "            #     break\n",
    "\n",
    "    # accuracy:\n",
    "    accuracy = correct / total\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # move to cpu:\n",
    "    all_labels = [label.cpu().numpy() for label in all_labels]\n",
    "    all_predictions = [prediction.cpu().numpy() for prediction in all_predictions]\n",
    "\n",
    "    # f1 score:\n",
    "    f1 = f1_score(all_labels, all_predictions)\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # confusion matrix:\n",
    "    matrix = confusion_matrix(all_labels, all_predictions)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(matrix, annot=True, fmt='g', cmap='Blues')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.show()\n",
    "\n",
    "test_siamese_network(trained_model, eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 0.9028\n",
      "Test F1 Score: 0.6405\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_siamese_network(trained_model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_test = eval_data.sample(1)\n",
    "# img1, img2, label = random_test.iloc[0]\n",
    "# img1 = img1.strip(\"()\")\n",
    "# img2 = img2.strip(\"()\")\n",
    "\n",
    "# # Load images\n",
    "# image1 = Image.open(img1).convert(\"RGB\")\n",
    "# image2 = Image.open(img2).convert(\"RGB\")\n",
    "\n",
    "# # Print Images\n",
    "# display(image1)\n",
    "# display(image2)\n",
    "\n",
    "# # Apply transformations\n",
    "# image1 = transform(image1).unsqueeze(0)\n",
    "# image2 = transform(image2).unsqueeze(0)\n",
    "\n",
    "# # Forward pass\n",
    "# output1, output2 = trained_model(image1, image2)\n",
    "\n",
    "# # Calculate the euclidean distance between the outputs\n",
    "# # diff = output1 - output2\n",
    "# # dist_sq = torch.sum(torch.pow(diff, 2), 1)\n",
    "# # dist = torch.sqrt(dist_sq)\n",
    "# dist = F.pairwise_distance(output1, output2)\n",
    "# print(f\"Distance: {dist.item()}\")\n",
    "\n",
    "# # Get predictions\n",
    "# predicted = (dist < 1.0).float()\n",
    "# true_label = 0 if label < 2 else 1\n",
    "\n",
    "# print(f\"Predicted: {predicted.item()}, Actual: {true_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca of the output:\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Get the output of the model\n",
    "outputs = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img1, img2, label in eval_loader:\n",
    "        output1, output2 = trained_model(img1, img2)\n",
    "        outputs.append(output1)\n",
    "        labels.append(label)\n",
    "\n",
    "outputs = torch.cat(outputs, dim=0)\n",
    "labels = torch.cat(labels, dim=0)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_outputs = pca.fit_transform(outputs)\n",
    "\n",
    "# Plot the PCA\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=pca_outputs[:, 0], y=pca_outputs[:, 1], hue=labels, palette='viridis')\n",
    "plt.title('PCA of the Siamese Network Output')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"model.pt\")\n",
    "# print(\"Model Saved Successfully\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_rows = full_data_paths[full_data_paths['similarity'].isna()].sample(5000)\n",
    "unlabeled_rows = unlabeled_rows[['image1_path', 'image2_path', 'similarity']]\n",
    "unlabeled_dataset = ImageSimilarityDataset(unlabeled_rows, transform=transform)\n",
    "data_loader = DataLoader(unlabeled_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "def active_learning_confident_samples(model, dataloader, margin=1.0, budget=100):\n",
    "    \"\"\"\n",
    "    Identify the least confident samples from the model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Siamese network.\n",
    "        dataloader: DataLoader for the dataset you want to evaluate.\n",
    "        margin: The margin used in the contrastive loss.\n",
    "        top_k: Number of least confident samples to return.\n",
    "    \n",
    "    Returns:\n",
    "        A list of the top_k least confident samples (input pairs and distances).\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    least_confident_samples = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for img1_path, img2_path, img1, img2, labels in tqdm(dataloader):\n",
    "            # Get the model outputs for both images\n",
    "            output1, output2 = model(img1, img2)\n",
    "            \n",
    "            # Calculate pairwise distance\n",
    "            distances = F.pairwise_distance(output1, output2)\n",
    "            \n",
    "            # Calculate confidence score (distance from the margin)\n",
    "            confidence_scores = torch.abs(distances - margin)\n",
    "\n",
    "            # Collect the least confident samples (small confidence score means high uncertainty)\n",
    "            for i in range(len(confidence_scores)):\n",
    "                least_confident_samples.append((img1_path[i], img2_path[i], distances[i].item(), confidence_scores[i].item()))\n",
    "\n",
    "    # Sort samples by confidence score (ascending, to get least confident samples)\n",
    "    least_confident_samples.sort(key=lambda x: x[3])\n",
    "\n",
    "    # Return the top_k least confident samples\n",
    "    return least_confident_samples[:budget]\n",
    "\n",
    "least_confident_samples = active_learning_confident_samples(trained_model, data_loader, margin=1.0, budget=100)\n",
    "print(least_confident_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: from confidence samples save into a csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
